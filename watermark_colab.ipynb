{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® CNN-Based Image Watermarking using DWT\n",
    "## Google Colab - Optimized Version\n",
    "\n",
    "This notebook trains and evaluates a deep learning watermarking system.\n",
    "\n",
    "**Features:**\n",
    "- Invisible watermark embedding\n",
    "- Robust against 7 attack types\n",
    "- Automatic evaluation with metrics\n",
    "- GPU accelerated training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", \"‚úì YES\" if tf.config.list_physical_devices('GPU') else \"‚úó NO\")\n",
    "print(\"\\n‚ö†Ô∏è If GPU is not available, go to: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (if not already cloned)\n",
    "import os\n",
    "if not os.path.exists('Watermarking-cnn'):\n",
    "    !git clone https://github.com/Mehulsri07/Watermarking-cnn.git\n",
    "    print(\"‚úì Repository cloned\")\n",
    "else:\n",
    "    print(\"‚úì Repository already exists\")\n",
    "\n",
    "# Change to project directory\n",
    "%cd Watermarking-cnn\n",
    "print(\"\\nüìÅ Current directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q tensorflow-wavelets opencv-python scikit-image matplotlib\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 2: Download Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample images from Lorem Picsum\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "def download_samples(num_train=20, num_test=5):\n",
    "    os.makedirs('train_images', exist_ok=True)\n",
    "    os.makedirs('test_images', exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloading {num_train} training images...\")\n",
    "    for i in range(num_train):\n",
    "        url = f\"https://picsum.photos/256/256?random={i}\"\n",
    "        urllib.request.urlretrieve(url, f\"train_images/train_{i:03d}.jpg\")\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"  Downloaded {i+1}/{num_train}\")\n",
    "    \n",
    "    print(f\"\\nDownloading {num_test} test images...\")\n",
    "    for i in range(num_test):\n",
    "        url = f\"https://picsum.photos/256/256?random={100+i}\"\n",
    "        urllib.request.urlretrieve(url, f\"test_images/test_{i:03d}.jpg\")\n",
    "    \n",
    "    print(f\"\\n‚úì Downloaded {num_train} training + {num_test} test images\")\n",
    "\n",
    "download_samples(num_train=20, num_test=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 3: Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 10          # Number of training epochs (increase for better results)\n",
    "BATCH_SIZE = 2       # Batch size (increase if you have more GPU memory)\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(\"\\nüí° Tip: Increase EPOCHS to 20-50 for better accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training and evaluation\n",
    "!python train_and_evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 5: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary metrics\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "# Show summary chart\n",
    "print(\"üìä Performance Summary:\")\n",
    "display(Image('config_1_baseline/evaluation_results/summary_metrics.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed results\n",
    "with open('config_1_baseline/evaluation_results/evaluation_report.json', 'r') as f:\n",
    "    report = json.load(f)\n",
    "\n",
    "print(\"\\nüìã Detailed Results:\\n\")\n",
    "print(\"=\"*80)\n",
    "for attack_name, stats in report['attack_statistics'].items():\n",
    "    print(f\"\\n{attack_name}:\")\n",
    "    print(f\"  PSNR: {stats['avg_psnr']:.2f} dB\")\n",
    "    print(f\"  SSIM: {stats['avg_ssim']:.4f}\")\n",
    "    print(f\"  BER:  {stats['avg_ber']:.2f}%\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample visualizations\n",
    "import glob\n",
    "\n",
    "print(\"\\nüñºÔ∏è Sample Visualizations:\\n\")\n",
    "image_files = glob.glob('config_1_baseline/evaluation_results/images/*.png')[:3]\n",
    "\n",
    "for img_file in image_files:\n",
    "    print(f\"\\n{os.path.basename(img_file)}:\")\n",
    "    display(Image(img_file, width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 6: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file with all results\n",
    "!zip -r results.zip config_1_baseline/\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('results.zip')\n",
    "\n",
    "print(\"‚úì Results downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Step 7: Test Custom Image (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your own image\n",
    "from google.colab import files\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "print(\"Upload an image to test watermarking:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    filename = list(uploaded.keys())[0]\n",
    "    print(f\"\\n‚úì Uploaded: {filename}\")\n",
    "    \n",
    "    # Process image\n",
    "    img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    \n",
    "    # Generate watermark\n",
    "    watermark = np.random.randint(0, 2, size=(256,)).astype(np.float32)\n",
    "    \n",
    "    # Load model\n",
    "    from models.wavetf_model import WaveTFModel\n",
    "    wavetf_model = WaveTFModel(image_size=(256, 256, 1), watermark_size=(256,))\n",
    "    model = wavetf_model.get_model()\n",
    "    model.load_weights('config_1_baseline/final_model_weights.h5')\n",
    "    \n",
    "    # Embed watermark\n",
    "    img_batch = np.expand_dims(img, axis=0)\n",
    "    wm_batch = np.expand_dims(watermark, axis=0)\n",
    "    attack_batch = np.array([[0]], dtype=np.int32)\n",
    "    \n",
    "    watermarked, extracted = model.predict([img_batch, wm_batch, attack_batch])\n",
    "    \n",
    "    # Save and display\n",
    "    cv2.imwrite('watermarked_output.png', (watermarked[0].squeeze() * 255).astype(np.uint8))\n",
    "    \n",
    "    print(\"\\nüì∏ Results:\")\n",
    "    display(IPImage('watermarked_output.png'))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from utils.metrics import calculate_psnr, calculate_ssim, calculate_ber\n",
    "    psnr = calculate_psnr(img_batch, watermarked)\n",
    "    ssim = calculate_ssim(img_batch, watermarked)\n",
    "    ber = calculate_ber(wm_batch, extracted)\n",
    "    \n",
    "    print(f\"\\nüìä Metrics:\")\n",
    "    print(f\"  PSNR: {psnr:.2f} dB\")\n",
    "    print(f\"  SSIM: {ssim:.4f}\")\n",
    "    print(f\"  BER:  {ber:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ Done!\n",
    "\n",
    "Your watermarking model is trained and evaluated. Check the results above!\n",
    "\n",
    "**Next Steps:**\n",
    "- Increase EPOCHS for better accuracy\n",
    "- Add more training images\n",
    "- Test with your own images\n",
    "- Download the trained model\n",
    "\n",
    "**Questions?** Open an issue on GitHub!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Watermark CNN - Optimized",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

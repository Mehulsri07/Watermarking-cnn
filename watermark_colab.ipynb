{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® CNN-Based Image Watermarking using DWT\n",
    "## Google Colab - Optimized Version\n",
    "\n",
    "This notebook trains and evaluates a deep learning watermarking system.\n",
    "\n",
    "**Features:**\n",
    "- Invisible watermark embedding\n",
    "- Robust against 7 attack types\n",
    "- Automatic evaluation with metrics\n",
    "- GPU accelerated training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", \"‚úì YES\" if tf.config.list_physical_devices('GPU') else \"‚úó NO\")\n",
    "print(\"\\n‚ö†Ô∏è If GPU is not available, go to: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (if not already cloned)\n",
    "import os\n",
    "\n",
    "# Clean up any existing directory first\n",
    "if os.path.exists('Watermarking-cnn'):\n",
    "    print(\"Removing existing directory...\")\n",
    "    !rm -rf Watermarking-cnn\n",
    "\n",
    "# Clone fresh\n",
    "print(\"Cloning repository...\")\n",
    "!git clone https://github.com/Mehulsri07/Watermarking-cnn.git\n",
    "\n",
    "# Change to project directory\n",
    "%cd Watermarking-cnn\n",
    "\n",
    "# Verify we're in the right place\n",
    "print(\"\\nüìÅ Current directory:\", os.getcwd())\n",
    "print(\"üìÇ Contents:\", os.listdir('.')[:10], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies with NumPy fix\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install -q 'numpy<2.0' tensorflow-wavelets tensorflow-addons opencv-python scikit-image 'matplotlib>=3.8.0'\n",
    "print(\"‚úì Dependencies installed\")\n",
    "\n",
    "# Verify NumPy version\n",
    "import numpy as np\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 2: Download Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample images from Lorem Picsum\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "def download_samples(num_train=80, num_test=20):\n",
    "    os.makedirs('train_images', exist_ok=True)\n",
    "    os.makedirs('test_images', exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloading {num_train} training images...\")\n",
    "    for i in range(num_train):\n",
    "        url = f\"https://picsum.photos/256/256?random={i}\"\n",
    "        urllib.request.urlretrieve(url, f\"train_images/train_{i:03d}.jpg\")\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"  Downloaded {i+1}/{num_train}\")\n",
    "    \n",
    "    print(f\"\\nDownloading {num_test} test images...\")\n",
    "    for i in range(num_test):\n",
    "        url = f\"https://picsum.photos/256/256?random={100+i}\"\n",
    "        urllib.request.urlretrieve(url, f\"test_images/test_{i:03d}.jpg\")\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"  Downloaded {i+1}/{num_test}\")\n",
    "    \n",
    "    print(f\"\\n‚úì Downloaded {num_train} training + {num_test} test images\")\n",
    "\n",
    "download_samples(num_train=80, num_test=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 3: Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration - Optimized for better results\n",
    "EPOCHS = 50          # Number of training epochs\n",
    "BATCH_SIZE = 10      # Batch size (using GPU memory efficiently)\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Training Images: 80\")\n",
    "print(f\"  Test Images: 20\")\n",
    "print(\"\\n‚è±Ô∏è Expected training time: ~15-20 minutes on GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify setup before training\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"Pre-training checks:\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check directories\n",
    "print(f\"\\nChecking required directories:\")\n",
    "for dir_name in ['models', 'attacks', 'data_loaders', 'utils']:\n",
    "    exists = os.path.exists(dir_name)\n",
    "    print(f\"  {'‚úì' if exists else '‚úó'} {dir_name}/\")\n",
    "    if exists:\n",
    "        # Check for __init__.py\n",
    "        init_exists = os.path.exists(os.path.join(dir_name, '__init__.py'))\n",
    "        print(f\"    {'‚úì' if init_exists else '‚úó'} __init__.py\")\n",
    "\n",
    "# Check images\n",
    "print(f\"\\nChecking images:\")\n",
    "train_count = len([f for f in os.listdir('train_images') if f.endswith(('.jpg', '.png'))]) if os.path.exists('train_images') else 0\n",
    "test_count = len([f for f in os.listdir('test_images') if f.endswith(('.jpg', '.png'))]) if os.path.exists('test_images') else 0\n",
    "print(f\"  Training images: {train_count}\")\n",
    "print(f\"  Test images: {test_count}\")\n",
    "\n",
    "# Test imports\n",
    "print(f\"\\nTesting imports:\")\n",
    "try:\n",
    "    from models.wavetf_model import WaveTFModel\n",
    "    print(\"  ‚úì models.wavetf_model\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚úó models.wavetf_model: {e}\")\n",
    "\n",
    "try:\n",
    "    from data_loaders.merged_data_loader import MergedDataLoader\n",
    "    print(\"  ‚úì data_loaders.merged_data_loader\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚úó data_loaders.merged_data_loader: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if train_count == 0 or test_count == 0:\n",
    "    print(\"‚ö†Ô∏è Warning: No images found! Run Step 2 first.\")\n",
    "else:\n",
    "    print(\"‚úì Ready to train!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training and evaluation\n",
    "!python train_and_evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 5: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training completed successfully\n",
    "import os\n",
    "\n",
    "print(\"Checking training results...\\n\")\n",
    "\n",
    "checks = {\n",
    "    'Model weights': 'config_1_baseline/final_model_weights.h5',\n",
    "    'Evaluation report': 'config_1_baseline/evaluation_results/evaluation_report.json',\n",
    "    'Summary chart': 'config_1_baseline/evaluation_results/summary_metrics.png',\n",
    "    'Result images': 'config_1_baseline/evaluation_results/images/'\n",
    "}\n",
    "\n",
    "all_good = True\n",
    "for name, path in checks.items():\n",
    "    if os.path.exists(path):\n",
    "        print(f\"‚úì {name}: Found\")\n",
    "    else:\n",
    "        print(f\"‚úó {name}: Missing\")\n",
    "        all_good = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_good:\n",
    "    print(\"‚úÖ Training completed successfully!\")\n",
    "    print(\"You can now view the results below.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Training may not have completed.\")\n",
    "    print(\"Please run the training cell (Step 4) first.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary metrics\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Check if results exist\n",
    "results_path = 'config_1_baseline/evaluation_results/summary_metrics.png'\n",
    "if os.path.exists(results_path):\n",
    "    print(\"üìä Performance Summary:\")\n",
    "    display(Image(results_path))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Results not found. Make sure training completed successfully.\")\n",
    "    print(\"Run the training cell above first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed results\n",
    "import os\n",
    "import json\n",
    "\n",
    "report_path = 'config_1_baseline/evaluation_results/evaluation_report.json'\n",
    "if os.path.exists(report_path):\n",
    "    with open(report_path, 'r') as f:\n",
    "        report = json.load(f)\n",
    "    \n",
    "    print(\"\\nüìã Detailed Results:\\n\")\n",
    "    print(\"=\"*80)\n",
    "    for attack_name, stats in report['attack_statistics'].items():\n",
    "        print(f\"\\n{attack_name}:\")\n",
    "        print(f\"  PSNR: {stats['avg_psnr']:.2f} dB\")\n",
    "        print(f\"  SSIM: {stats['avg_ssim']:.4f}\")\n",
    "        print(f\"  BER:  {stats['avg_ber']:.2f}%\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Evaluation report not found.\")\n",
    "    print(\"Make sure training completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample visualizations\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "images_dir = 'config_1_baseline/evaluation_results/images/'\n",
    "if os.path.exists(images_dir):\n",
    "    print(\"\\nüñºÔ∏è Sample Visualizations:\\n\")\n",
    "    image_files = glob.glob(images_dir + '*.png')[:3]\n",
    "    \n",
    "    if image_files:\n",
    "        for img_file in image_files:\n",
    "            print(f\"\\n{os.path.basename(img_file)}:\")\n",
    "            display(Image(img_file, width=800))\n",
    "    else:\n",
    "        print(\"No visualization images found.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Results directory not found.\")\n",
    "    print(\"Make sure training completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 6: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file with all results\n",
    "!zip -r results.zip config_1_baseline/\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('results.zip')\n",
    "\n",
    "print(\"‚úì Results downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Step 7: Test Custom Image (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your own image\n",
    "from google.colab import files\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "print(\"Upload an image to test watermarking:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    filename = list(uploaded.keys())[0]\n",
    "    print(f\"\\n‚úì Uploaded: {filename}\")\n",
    "    \n",
    "    # Process image\n",
    "    img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    \n",
    "    # Generate watermark\n",
    "    watermark = np.random.randint(0, 2, size=(256,)).astype(np.float32)\n",
    "    \n",
    "    # Load model\n",
    "    from models.wavetf_model import WaveTFModel\n",
    "    wavetf_model = WaveTFModel(image_size=(256, 256, 1), watermark_size=(256,))\n",
    "    model = wavetf_model.get_model()\n",
    "    model.load_weights('config_1_baseline/final_model_weights.h5')\n",
    "    \n",
    "    # Embed watermark\n",
    "    img_batch = np.expand_dims(img, axis=0)\n",
    "    wm_batch = np.expand_dims(watermark, axis=0)\n",
    "    attack_batch = np.array([[0]], dtype=np.int32)\n",
    "    \n",
    "    watermarked, extracted = model.predict([img_batch, wm_batch, attack_batch])\n",
    "    \n",
    "    # Save and display\n",
    "    cv2.imwrite('watermarked_output.png', (watermarked[0].squeeze() * 255).astype(np.uint8))\n",
    "    \n",
    "    print(\"\\nüì∏ Results:\")\n",
    "    display(IPImage('watermarked_output.png'))\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from utils.metrics import calculate_psnr, calculate_ssim, calculate_ber\n",
    "    psnr = calculate_psnr(img_batch, watermarked)\n",
    "    ssim = calculate_ssim(img_batch, watermarked)\n",
    "    ber = calculate_ber(wm_batch, extracted)\n",
    "    \n",
    "    print(f\"\\nüìä Metrics:\")\n",
    "    print(f\"  PSNR: {psnr:.2f} dB\")\n",
    "    print(f\"  SSIM: {ssim:.4f}\")\n",
    "    print(f\"  BER:  {ber:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úÖ Done!\n",
    "\n",
    "Your watermarking model is trained and evaluated. Check the results above!\n",
    "\n",
    "**Next Steps:**\n",
    "- Increase EPOCHS for better accuracy\n",
    "- Add more training images\n",
    "- Test with your own images\n",
    "- Download the trained model\n",
    "\n",
    "**Questions?** Open an issue on GitHub!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Watermark CNN - Optimized",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
